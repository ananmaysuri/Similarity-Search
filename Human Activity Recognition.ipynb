{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Torch version: 1.7.1\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "\n",
    "print(\"Torch version:\", torch.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "! rm ./clip_classes/.DS_Store"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['sleeping', 'sitting', 'jogging']"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "#our the classes and images we want to test are stored in folders in the test set\n",
    "class_names = os.listdir('./clip_classes/')\n",
    "class_names.remove('_tokenization.txt')\n",
    "class_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A picture of a person sleeping\r\n",
      "A picture of a person sitting\r\n",
      "A picture of a person jogging\r\n"
     ]
    }
   ],
   "source": [
    "#we auto generate some example tokenizations in Roboflow but you should edit this file to try out your own prompts\n",
    "#CLIP gets a lot better with the right prompting!\n",
    "#be sure the tokenizations are in the same order as your class_names above!\n",
    "%cat ./clip_classes/_tokenization.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting ./clip_classes/_tokenization.txt\n"
     ]
    }
   ],
   "source": [
    "%%writefile ./clip_classes/_tokenization.txt\n",
    "A picture of a person sleeping\n",
    "A picture of a person sitting\n",
    "A picture of a person jogging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "candidate_captions = []\n",
    "with open('./clip_classes/_tokenization.txt') as f:\n",
    "    candidate_captions = f.read().splitlines()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sleeping4.jpg\n",
      "Prediction Class : sleeping,  Label : 0,  Confidence : 90.7468\n",
      "sleeping5.jpg\n",
      "Prediction Class : sleeping,  Label : 0,  Confidence : 99.9622\n",
      "sleeping7.jpg\n",
      "Prediction Class : sleeping,  Label : 0,  Confidence : 99.9920\n",
      "sleeping6.jpg\n",
      "Prediction Class : sleeping,  Label : 0,  Confidence : 99.9726\n",
      "sleeping1.jpg\n",
      "Prediction Class : sleeping,  Label : 0,  Confidence : 99.9823\n",
      "sleeping8.jpg\n",
      "Prediction Class : sleeping,  Label : 0,  Confidence : 99.8401\n",
      "sleeping9.jpg\n",
      "Prediction Class : sleeping,  Label : 0,  Confidence : 99.0630\n",
      "sleeping10.jpg\n",
      "Prediction Class : sleeping,  Label : 0,  Confidence : 98.8622\n",
      "\n",
      "Accuracy on class sleeping is : 100.0%\n",
      "\n",
      "\n",
      "sitting6.jpg\n",
      "Prediction Class : sitting,  Label : 1,  Confidence : 99.9006\n",
      "sitting7.jpg\n",
      "Prediction Class : sitting,  Label : 1,  Confidence : 99.7139\n",
      "sitting5.jpg\n",
      "Prediction Class : sitting,  Label : 1,  Confidence : 97.7814\n",
      "sitting4.jpg\n",
      "Prediction Class : sitting,  Label : 1,  Confidence : 99.9648\n",
      "sitting1.jpg\n",
      "Prediction Class : sitting,  Label : 1,  Confidence : 99.6433\n",
      "sitting3.jpg\n",
      "Prediction Class : sitting,  Label : 1,  Confidence : 99.5685\n",
      "sitting2.jpg\n",
      "Prediction Class : sitting,  Label : 1,  Confidence : 99.4457\n",
      "sitting10.jpg\n",
      "Prediction Class : sitting,  Label : 1,  Confidence : 95.1932\n",
      "sitting9.jpg\n",
      "Prediction Class : sitting,  Label : 1,  Confidence : 97.8256\n",
      "sitting8.jpg\n",
      "Prediction Class : sitting,  Label : 1,  Confidence : 99.5779\n",
      "\n",
      "Accuracy on class sitting is : 100.0%\n",
      "\n",
      "\n",
      "jogging9.jpg\n",
      "Prediction Class : jogging,  Label : 2,  Confidence : 99.9539\n",
      "jogging10.jpg\n",
      "Prediction Class : jogging,  Label : 2,  Confidence : 99.7559\n",
      "jogging2.jpg\n",
      "Prediction Class : jogging,  Label : 2,  Confidence : 99.9810\n",
      "jogging3.jpg\n",
      "Prediction Class : jogging,  Label : 2,  Confidence : 99.9861\n",
      "jogging1.jpg\n",
      "Prediction Class : jogging,  Label : 2,  Confidence : 99.9889\n",
      "jogging4.jpg\n",
      "Prediction Class : jogging,  Label : 2,  Confidence : 99.8759\n",
      "jogging5.jpg\n",
      "Prediction Class : jogging,  Label : 2,  Confidence : 99.9963\n",
      "jogging7.jpg\n",
      "Prediction Class : jogging,  Label : 2,  Confidence : 99.9598\n",
      "jogging6.jpg\n",
      "Prediction Class : jogging,  Label : 2,  Confidence : 99.9838\n",
      "\n",
      "Accuracy on class jogging is : 100.0%\n",
      "\n",
      "\n",
      "\n",
      "Overall Accuracy is : 100.0%\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import clip\n",
    "from PIL import Image\n",
    "import glob\n",
    "\n",
    "def argmax(iterable):\n",
    "    return max(enumerate(iterable), key=lambda x: x[1])[0]\n",
    "\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "model, transform = clip.load(\"ViT-B/32\", device=device)\n",
    "\n",
    "correct = []\n",
    "\n",
    "#define our target classificaitons, you can should experiment with these strings of text as you see fit, though, make sure they are in the same order as your class names above\n",
    "text = clip.tokenize(candidate_captions).to(device)\n",
    "\n",
    "for cls in class_names:\n",
    "    class_correct = []\n",
    "    test_imgs = glob.glob('./clip_classes/' + cls + '/*.jpg')\n",
    "    for img in test_imgs:\n",
    "        print(img.split('/')[-1])\n",
    "        image = transform(Image.open(img)).unsqueeze(0).to(device)\n",
    "        with torch.no_grad():\n",
    "            image_features = model.encode_image(image)\n",
    "            text_features = model.encode_text(text)\n",
    "            \n",
    "            logits_per_image, logits_per_text = model(image, text)\n",
    "            probs = logits_per_image.softmax(dim=-1).cpu().numpy()\n",
    "\n",
    "            pred = class_names[argmax(list(probs)[0])]\n",
    "            print(\"Prediction Class : %s,  Label : %d,  Confidence : %.4f\" % (pred, argmax(list(probs)[0]), probs[0][argmax(list(probs)[0])]*100))\n",
    "            if pred == cls:\n",
    "                correct.append(1)\n",
    "                class_correct.append(1)\n",
    "            else:\n",
    "                correct.append(0)\n",
    "                class_correct.append(0)\n",
    "    \n",
    "    print('\\nAccuracy on class ' + cls + ' is : ' + str(sum(class_correct)/len(class_correct)*100) + \"%\\n\\n\")\n",
    "print('\\nOverall Accuracy is : ' + str(sum(correct)/len(correct)*100) + \"%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
